{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-QreKZI06NT"
   },
   "source": [
    "# COCO DATASET GATHERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3DkfDsiwrpg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: /usr/local/bin/pip: bad interpreter: /usr/local/opt/python/bin/python3.6: no such file or directory\n",
      "Clonando en 'cocoapi'...\n",
      "remote: Enumerating objects: 975, done.\u001b[K\n",
      "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
      "\u001b[KRecibiendo objetos: 100% (975/975), 11.72 MiB | 14.17 MiB/s, listo.\n",
      "\u001b[KResolviendo deltas: 100% (576/576), listo.\n",
      "/Users/Anita/Documents/HMDA/TFM/CODE/TFM/U-Net/UNET-On-COCO-master/cocoapi/PythonAPI/cocoapi\n",
      "RefactoringTool: Skipping optional fixer: buffer\n",
      "RefactoringTool: Skipping optional fixer: idioms\n",
      "RefactoringTool: Skipping optional fixer: set_literal\n",
      "RefactoringTool: Skipping optional fixer: ws_comma\n",
      "RefactoringTool: No changes to ./PythonAPI/setup.py\n",
      "RefactoringTool: No changes to ./PythonAPI/pycocotools/__init__.py\n",
      "RefactoringTool: Refactored ./PythonAPI/pycocotools/coco.py\n",
      "--- ./PythonAPI/pycocotools/coco.py\t(original)\n",
      "+++ ./PythonAPI/pycocotools/coco.py\t(refactored)\n",
      "@@ -58,7 +58,7 @@\n",
      " import sys\n",
      " PYTHON_VERSION = sys.version_info[0]\n",
      " if PYTHON_VERSION == 2:\n",
      "-    from urllib import urlretrieve\n",
      "+    from urllib.request import urlretrieve\n",
      " elif PYTHON_VERSION == 3:\n",
      "     from urllib.request import urlretrieve\n",
      " \n",
      "@@ -83,7 +83,7 @@\n",
      "             tic = time.time()\n",
      "             dataset = json.load(open(annotation_file, 'r'))\n",
      "             assert type(dataset)==dict, 'annotation file format {} not supported'.format(type(dataset))\n",
      "-            print('Done (t={:0.2f}s)'.format(time.time()- tic))\n",
      "+            print(('Done (t={:0.2f}s)'.format(time.time()- tic)))\n",
      "             self.dataset = dataset\n",
      "             self.createIndex()\n",
      " \n",
      "@@ -123,8 +123,8 @@\n",
      "         Print information about the annotation file.\n",
      "         :return:\n",
      "         \"\"\"\n",
      "-        for key, value in self.dataset['info'].items():\n",
      "-            print('{}: {}'.format(key, value))\n",
      "+        for key, value in list(self.dataset['info'].items()):\n",
      "+            print(('{}: {}'.format(key, value)))\n",
      " \n",
      "     def getAnnIds(self, imgIds=[], catIds=[], areaRng=[], iscrowd=None):\n",
      "         \"\"\"\n",
      "@@ -187,7 +187,7 @@\n",
      "         catIds = catIds if _isArrayLike(catIds) else [catIds]\n",
      " \n",
      "         if len(imgIds) == len(catIds) == 0:\n",
      "-            ids = self.imgs.keys()\n",
      "+            ids = list(self.imgs.keys())\n",
      "         else:\n",
      "             ids = set(imgIds)\n",
      "             for i, catId in enumerate(catIds):\n",
      "@@ -300,7 +300,7 @@\n",
      "             ax.add_collection(p)\n",
      "         elif datasetType == 'captions':\n",
      "             for ann in anns:\n",
      "-                print(ann['caption'])\n",
      "+                print((ann['caption']))\n",
      " \n",
      "     def loadRes(self, resFile):\n",
      "         \"\"\"\n",
      "@@ -313,7 +313,7 @@\n",
      " \n",
      "         print('Loading and preparing results...')\n",
      "         tic = time.time()\n",
      "-        if type(resFile) == str or (PYTHON_VERSION == 2 and type(resFile) == unicode):\n",
      "+        if type(resFile) == str or (PYTHON_VERSION == 2 and type(resFile) == str):\n",
      "             anns = json.load(open(resFile))\n",
      "         elif type(resFile) == np.ndarray:\n",
      "             anns = self.loadNumpyAnnotations(resFile)\n",
      "@@ -357,7 +357,7 @@\n",
      "                 ann['area'] = (x1-x0)*(y1-y0)\n",
      "                 ann['id'] = id + 1\n",
      "                 ann['bbox'] = [x0,y0,x1-x0,y1-y0]\n",
      "-        print('DONE (t={:0.2f}s)'.format(time.time()- tic))\n",
      "+        print(('DONE (t={:0.2f}s)'.format(time.time()- tic)))\n",
      " \n",
      "         res.dataset['annotations'] = anns\n",
      "         res.createIndex()\n",
      "@@ -374,7 +374,7 @@\n",
      "             print('Please specify target directory')\n",
      "             return -1\n",
      "         if len(imgIds) == 0:\n",
      "-            imgs = self.imgs.values()\n",
      "+            imgs = list(self.imgs.values())\n",
      "         else:\n",
      "             imgs = self.loadImgs(imgIds)\n",
      "         N = len(imgs)\n",
      "@@ -385,7 +385,7 @@\n",
      "             fname = os.path.join(tarDir, img['file_name'])\n",
      "             if not os.path.exists(fname):\n",
      "                 urlretrieve(img['coco_url'], fname)\n",
      "-            print('downloaded {}/{} images (t={:0.1f}s)'.format(i, N, time.time()- tic))\n",
      "+            print(('downloaded {}/{} images (t={:0.1f}s)'.format(i, N, time.time()- tic)))\n",
      " \n",
      "     def loadNumpyAnnotations(self, data):\n",
      "         \"\"\"\n",
      "@@ -395,13 +395,13 @@\n",
      "         \"\"\"\n",
      "         print('Converting ndarray to lists...')\n",
      "         assert(type(data) == np.ndarray)\n",
      "-        print(data.shape)\n",
      "+        print((data.shape))\n",
      "         assert(data.shape[1] == 7)\n",
      "         N = data.shape[0]\n",
      "         ann = []\n",
      "         for i in range(N):\n",
      "             if i % 1000000 == 0:\n",
      "-                print('{}/{}'.format(i,N))\n",
      "+                print(('{}/{}'.format(i,N)))\n",
      "             ann += [{\n",
      "                 'image_id'  : int(data[i, 0]),\n",
      "                 'bbox'  : [ data[i, 1], data[i, 2], data[i, 3], data[i, 4] ],\n",
      "RefactoringTool: Refactored ./PythonAPI/pycocotools/cocoeval.py\n",
      "--- ./PythonAPI/pycocotools/cocoeval.py\t(original)\n",
      "+++ ./PythonAPI/pycocotools/cocoeval.py\t(refactored)\n",
      "@@ -129,8 +129,8 @@\n",
      "         # add backward compatibility if useSegm is specified in params\n",
      "         if not p.useSegm is None:\n",
      "             p.iouType = 'segm' if p.useSegm == 1 else 'bbox'\n",
      "-            print('useSegm (deprecated) is not None. Running {} evaluation'.format(p.iouType))\n",
      "-        print('Evaluate annotation type *{}*'.format(p.iouType))\n",
      "+            print(('useSegm (deprecated) is not None. Running {} evaluation'.format(p.iouType)))\n",
      "+        print(('Evaluate annotation type *{}*'.format(p.iouType)))\n",
      "         p.imgIds = list(np.unique(p.imgIds))\n",
      "         if p.useCats:\n",
      "             p.catIds = list(np.unique(p.catIds))\n",
      "@@ -158,7 +158,7 @@\n",
      "              ]\n",
      "         self._paramsEval = copy.deepcopy(self.params)\n",
      "         toc = time.time()\n",
      "-        print('DONE (t={:0.2f}s).'.format(toc-tic))\n",
      "+        print(('DONE (t={:0.2f}s).'.format(toc-tic)))\n",
      " \n",
      "     def computeIoU(self, imgId, catId):\n",
      "         p = self.params\n",
      "@@ -345,7 +345,7 @@\n",
      "         # get inds to evaluate\n",
      "         k_list = [n for n, k in enumerate(p.catIds)  if k in setK]\n",
      "         m_list = [m for n, m in enumerate(p.maxDets) if m in setM]\n",
      "-        a_list = [n for n, a in enumerate(map(lambda x: tuple(x), p.areaRng)) if a in setA]\n",
      "+        a_list = [n for n, a in enumerate([tuple(x) for x in p.areaRng]) if a in setA]\n",
      "         i_list = [n for n, i in enumerate(p.imgIds)  if i in setI]\n",
      "         I0 = len(_pe.imgIds)\n",
      "         A0 = len(_pe.areaRng)\n",
      "@@ -417,7 +417,7 @@\n",
      "             'scores': scores,\n",
      "         }\n",
      "         toc = time.time()\n",
      "-        print('DONE (t={:0.2f}s).'.format( toc-tic))\n",
      "+        print(('DONE (t={:0.2f}s).'.format( toc-tic)))\n",
      " \n",
      "     def summarize(self):\n",
      "         '''\n",
      "@@ -453,7 +453,7 @@\n",
      "                 mean_s = -1\n",
      "             else:\n",
      "                 mean_s = np.mean(s[s>-1])\n",
      "-            print(iStr.format(titleStr, typeStr, iouStr, areaRng, maxDets, mean_s))\n",
      "+            print((iStr.format(titleStr, typeStr, iouStr, areaRng, maxDets, mean_s)))\n",
      "             return mean_s\n",
      "         def _summarizeDets():\n",
      "             stats = np.zeros((12,))\n",
      "RefactoringTool: No changes to ./PythonAPI/pycocotools/mask.py\n",
      "RefactoringTool: Files that were modified:\n",
      "RefactoringTool: ./PythonAPI/setup.py\n",
      "RefactoringTool: ./PythonAPI/pycocotools/__init__.py\n",
      "RefactoringTool: ./PythonAPI/pycocotools/coco.py\n",
      "RefactoringTool: ./PythonAPI/pycocotools/cocoeval.py\n",
      "RefactoringTool: ./PythonAPI/pycocotools/mask.py\n",
      "/Users/Anita/Documents/HMDA/TFM/CODE/TFM/U-Net/UNET-On-COCO-master/cocoapi/PythonAPI/cocoapi/PythonAPI\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Anita/Documents/HMDA/TFM/CODE/TFM/U-Net/UNET-On-COCO-master/cocoapi/PythonAPI/cocoapi/PythonAPI/setup.py\", line 2, in <module>\n",
      "    import numpy as np\n",
      "ModuleNotFoundError: No module named 'numpy'\n",
      "zsh:1: /usr/local/bin/pip: bad interpreter: /usr/local/opt/python/bin/python3.6: no such file or directory\n",
      "Collecting cython\n",
      "  Downloading Cython-0.29.30-py2.py3-none-any.whl (985 kB)\n",
      "\u001b[K     |████████████████████████████████| 985 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: cython\n",
      "Successfully installed cython-0.29.30\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!wget http://images.cocodataset.org/zips/train2014.zip#\n",
    "#!unzip -q train2014.zip\n",
    "#!wget http://images.cocodataset.org/zips/val2014.zip\n",
    "#!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
    "#!unzip -q val2014.zip\n",
    "#!unzip -q annotations_trainval2014.zip\n",
    "\n",
    "\n",
    "! pip install 2to3\n",
    "!git clone https://github.com/cocodataset/cocoapi.git\n",
    "%cd cocoapi\n",
    "!2to3 . -w\n",
    "%cd PythonAPI\n",
    "!python3 setup.py install\n",
    "!pip install -U pycocotools\n",
    "!pip3 install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fT6zZ-D51LWQ"
   },
   "outputs": [],
   "source": [
    "#%cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnF0aYFB1OXn"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools._mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-82a23d9bc1fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importing Data From COCO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcocoeval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmaskUtils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/HMDA/TFM/CODE/TFM/U-Net/UNET-On-COCO-master/cocoapi/PythonAPI/cocoapi/PythonAPI/pycocotools/coco.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmaskUtils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/HMDA/TFM/CODE/TFM/U-Net/UNET-On-COCO-master/cocoapi/PythonAPI/cocoapi/PythonAPI/pycocotools/mask.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__author__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tsungyi'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Interface for manipulating masks stored in RLE format.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools._mask'"
     ]
    }
   ],
   "source": [
    "# Importing Data From COCO\n",
    "\n",
    "from pycocotools import coco, cocoeval, _mask\n",
    "from pycocotools import mask as maskUtils \n",
    "import array\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import os\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UUWcLqnJ1SUG"
   },
   "outputs": [],
   "source": [
    "CATEGORY_NAMES=['person']\n",
    "\n",
    "ANNOTATION_FILE_VAL = '/content/annotations/instances_val2014.json'\n",
    "ANNOTATION_FILE_TRAIN = '/content/annotations/instances_train2014.json'\n",
    "\n",
    "\n",
    "coco_train = coco.COCO(ANNOTATION_FILE_TRAIN)\n",
    "catIds_train = coco_train.getCatIds(catNms=CATEGORY_NAMES);\n",
    "imgIds_train = coco_train.getImgIds(catIds=catIds_train);\n",
    "imgDict_train = coco_train.loadImgs(imgIds_train)\n",
    "len(imgIds_train) , len(catIds_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "coco_val = coco.COCO(ANNOTATION_FILE_VAL)\n",
    "catIds_val = coco_val.getCatIds(catNms=CATEGORY_NAMES);\n",
    "imgIds_val = coco_val.getImgIds(catIds=catIds_val);\n",
    "imgDict_val = coco_val.loadImgs(imgIds_val)\n",
    "len(imgIds_val) , len(catIds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9akfTem1Ue-"
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "shuffle(imgIds_train)\n",
    "shuffle(imgIds_val)\n",
    "\n",
    "imgIds_train = imgIds_train[0:6000]\n",
    "imgIds_val = imgIds_val[0:600]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIktAjPp1Xs0"
   },
   "outputs": [],
   "source": [
    "train_images_person = [\"COCO_train2014_{0:012d}.jpg\".format(ids) for ids in imgIds_train]\n",
    "val_images_person = [\"COCO_val2014_{0:012d}.jpg\".format(ids) for ids in imgIds_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cD2mRyK71bSE"
   },
   "outputs": [],
   "source": [
    "print(len(train_images_person) , len(val_images_person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDxYUzZT1crY"
   },
   "outputs": [],
   "source": [
    "train_images_person = [\"COCO_train2014_{0:012d}.jpg\".format(ids) for ids in imgIds_train]\n",
    "print(train_images_person)\n",
    "del_img_train = set(os.listdir(\"/content/train2014\")) - set(train_images_person)\n",
    "for file_name in del_img_train:\n",
    "  file_name = \"/content/train2014/\" + file_name\n",
    "  if os.path.exists(file_name):\n",
    "    os.remove(file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gWAno9N1dUE"
   },
   "outputs": [],
   "source": [
    "print(len(os.listdir(\"/content/train2014\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KAeyJbE71fUC"
   },
   "outputs": [],
   "source": [
    "val_images_person = [\"COCO_val2014_{0:012d}.jpg\".format(ids) for ids in imgIds_val]\n",
    "print(val_images_person)\n",
    "del_img_val = set(os.listdir(\"/content/val2014\")) - set(val_images_person)\n",
    "for file_name in del_img_val:\n",
    "  file_name = \"/content/val2014/\" + file_name\n",
    "  if os.path.exists(file_name):\n",
    "    os.remove(file_name)\n",
    "\n",
    "len(os.listdir(\"/content/val2014\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UyiCRQGd1hVt"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHhhJuEw1mvV"
   },
   "outputs": [],
   "source": [
    "!mkdir mask_train_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3W4zM_SZ1new"
   },
   "outputs": [],
   "source": [
    "count = 0 \n",
    "\n",
    "for ID in imgIds_train:\n",
    "\n",
    "  file_path = \"/content/mask_train_2014/COCO_train2014_{0:012d}.jpg\".format(ID)\n",
    "  \n",
    "  sampleImgIds = coco_train.getImgIds(imgIds = [ID])\n",
    "  sampleImgDict = coco_train.loadImgs(sampleImgIds[np.random.randint(0,len(sampleImgIds))])[0]\n",
    "\n",
    "  annIds = coco_train.getAnnIds(imgIds=sampleImgDict['id'], catIds=catIds_train, iscrowd=0)\n",
    "  anns = coco_train.loadAnns(annIds)\n",
    "\n",
    "\n",
    "  mask = coco_train.annToMask(anns[0])\n",
    "  for i in range(len(anns)):\n",
    "      mask = mask | coco_train.annToMask(anns[i])\n",
    "  \n",
    "  mask = Image.fromarray(mask * 255 , mode = \"L\")\n",
    "  mask.save(file_path)\n",
    "  count = count + 1\n",
    "  print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBAlOCAg1s02"
   },
   "outputs": [],
   "source": [
    "!mkdir mask_val_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdcMDJGY1ui7"
   },
   "outputs": [],
   "source": [
    "count = 0 \n",
    "for ID in imgIds_val:\n",
    "\n",
    "  file_path = \"/content/mask_val_2014/COCO_val2014_{0:012d}.jpg\".format(ID)\n",
    "  \n",
    "  sampleImgIds = coco_val.getImgIds(imgIds = [ID])\n",
    "  sampleImgDict = coco_val.loadImgs(sampleImgIds[np.random.randint(0,len(sampleImgIds))])[0]\n",
    "\n",
    "  annIds = coco_val.getAnnIds(imgIds=sampleImgDict['id'], catIds=catIds_val, iscrowd=0)\n",
    "  anns = coco_val.loadAnns(annIds)\n",
    "\n",
    "\n",
    "  mask = coco_val.annToMask(anns[0])\n",
    "  for i in range(len(anns)):\n",
    "      mask = mask | coco_val.annToMask(anns[i])\n",
    "  \n",
    "  mask = Image.fromarray(mask * 255 , mode = \"L\")\n",
    "  mask.save(file_path)\n",
    "  \n",
    "  count = count + 1\n",
    "  print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-OMmybC1v1W"
   },
   "outputs": [],
   "source": [
    "!rm -rf annotations/\n",
    "!rm -rf train2014.zip\n",
    "!rm -rf val2014.zip\n",
    "!rm -rf annotations_trainval2014.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_rmAwLIezXG"
   },
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJbmPHNceazg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "\n",
    "\n",
    "seed = 2019\n",
    "\n",
    "random.seed = seed\n",
    "np.random.seed = seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrV1_sQOevZ9"
   },
   "outputs": [],
   "source": [
    "class DataGen(keras.utils.Sequence):\n",
    "  \n",
    "  def __init__(self , path_input , path_mask , batch_size = 8 , image_size = 128):\n",
    "    \n",
    "    self.ids = os.listdir(path_input)\n",
    "    self.path_input = path_input\n",
    "    self.path_mask = path_mask\n",
    "    self.batch_size = batch_size\n",
    "    self.image_size = image_size\n",
    "    self.on_epoch_end()\n",
    "  \n",
    "  def __load__(self , id_name):\n",
    "    \n",
    "    image_path = os.path.join(self.path_input , id_name)\n",
    "    mask_path = os.path.join(self.path_mask , id_name) \n",
    "    \n",
    "    image = cv2.imread(image_path , 1) # 1 specifies RGB format\n",
    "    image = cv2.resize(image , (self.image_size , self.image_size)) # resizing before inserting to the network\n",
    "    \n",
    "    mask = cv2.imread(mask_path , -1)\n",
    "    mask = cv2.resize(mask , (self.image_size , self.image_size))\n",
    "    mask = mask.reshape((self.image_size , self.image_size , 1))\n",
    "      \n",
    "    #normalize image\n",
    "    image = image / 255.0\n",
    "    mask = mask / 255.0\n",
    "    \n",
    "    return image , mask\n",
    "  \n",
    "  def __getitem__(self , index):\n",
    "    \n",
    "    if (index + 1)*self.batch_size > len(self.ids):\n",
    "      self.batch_size = len(self.ids) - index * self.batch_size\n",
    "        \n",
    "    file_batch = self.ids[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for id_name in file_batch : \n",
    "      \n",
    "      _img , _mask = self.__load__(id_name)\n",
    "      images.append(_img)\n",
    "      masks.append(_mask)\n",
    "    \n",
    "    \n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    \n",
    "    return images , masks\n",
    "  \n",
    "  \n",
    "  def on_epoch_end(self):\n",
    "    pass\n",
    "  \n",
    "  \n",
    "  def __len__(self):\n",
    "    \n",
    "    return int(np.ceil(len(self.ids) / float(self.batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8L3_Slh1e2vZ"
   },
   "source": [
    "#UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65_xh2VYe2M_"
   },
   "outputs": [],
   "source": [
    "def down_block(\n",
    "    input_tensor,\n",
    "    no_filters,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    max_pool_window=(2, 2),\n",
    "    max_pool_stride=(2, 2)\n",
    "):\n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(input_tensor)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "\n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(conv)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    # conv for skip connection\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "\n",
    "    pool = MaxPooling2D(pool_size=max_pool_window, strides=max_pool_stride)(conv)\n",
    "\n",
    "    return conv, pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8FaVzvm3fESd"
   },
   "outputs": [],
   "source": [
    "def bottle_neck(\n",
    "    input_tensor,\n",
    "    no_filters,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\"\n",
    "):\n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(input_tensor)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "\n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(conv)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSzLN6m6fGMs"
   },
   "outputs": [],
   "source": [
    "def up_block(    \n",
    "    input_tensor,\n",
    "    no_filters,\n",
    "    skip_connection, \n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    upsampling_factor = (2,2),\n",
    "    max_pool_window = (2,2),\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\"):\n",
    "    \n",
    "    \n",
    "    conv = Conv2D(\n",
    "        filters = no_filters,\n",
    "        kernel_size= max_pool_window,\n",
    "        strides = strides,\n",
    "        activation = None,\n",
    "        padding = padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(UpSampling2D(size = upsampling_factor)(input_tensor))\n",
    "    \n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv) \n",
    "    \n",
    "    \n",
    "    conv = concatenate( [skip_connection , conv]  , axis = -1)\n",
    "    \n",
    "    \n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(conv)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "\n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(conv)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "    \n",
    "    return conv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LUtzcZVfG3o"
   },
   "outputs": [],
   "source": [
    "def output_block(input_tensor,\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\"\n",
    "):\n",
    "    \n",
    "    conv = Conv2D(\n",
    "        filters=2,\n",
    "        kernel_size=(3,3),\n",
    "        strides=(1,1),\n",
    "        activation=\"relu\",\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(input_tensor)\n",
    "    \n",
    "    \n",
    "    conv = Conv2D(\n",
    "        filters=1,\n",
    "        kernel_size=(1,1),\n",
    "        strides=(1,1),\n",
    "        activation=\"sigmoid\",\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(conv)\n",
    "    \n",
    "    \n",
    "    return conv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOEfWxYnfJho"
   },
   "outputs": [],
   "source": [
    "def UNet(input_shape = (128,128,3)):\n",
    "    \n",
    "    filter_size = [64,128,256,512,1024]\n",
    "    \n",
    "    inputs = Input(shape = input_shape)\n",
    "    \n",
    "    d1 , p1 = down_block(input_tensor= inputs,\n",
    "                         no_filters=filter_size[0],\n",
    "                         kernel_size = (3,3),\n",
    "                         strides=(1,1),\n",
    "                         padding=\"same\",\n",
    "                         kernel_initializer=\"he_normal\",\n",
    "                         max_pool_window=(2,2),\n",
    "                         max_pool_stride=(2,2))\n",
    "    \n",
    "    \n",
    "    d2 , p2 = down_block(input_tensor= p1,\n",
    "                         no_filters=filter_size[1],\n",
    "                         kernel_size = (3,3),\n",
    "                         strides=(1,1),\n",
    "                         padding=\"same\",\n",
    "                         kernel_initializer=\"he_normal\",\n",
    "                         max_pool_window=(2,2),\n",
    "                         max_pool_stride=(2,2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    d3 , p3 = down_block(input_tensor= p2,\n",
    "                         no_filters=filter_size[2],\n",
    "                         kernel_size = (3,3),\n",
    "                         strides=(1,1),\n",
    "                         padding=\"same\",\n",
    "                         kernel_initializer=\"he_normal\",\n",
    "                         max_pool_window=(2,2),\n",
    "                         max_pool_stride=(2,2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    d4 , p4 = down_block(input_tensor= p3,\n",
    "                         no_filters=filter_size[3],\n",
    "                         kernel_size = (3,3),\n",
    "                         strides=(1,1),\n",
    "                         padding=\"same\",\n",
    "                         kernel_initializer=\"he_normal\",\n",
    "                         max_pool_window=(2,2),\n",
    "                         max_pool_stride=(2,2))\n",
    "    \n",
    "    \n",
    "    b = bottle_neck(input_tensor= p4,\n",
    "                         no_filters=filter_size[4],\n",
    "                         kernel_size = (3,3),\n",
    "                         strides=(1,1),\n",
    "                         padding=\"same\",\n",
    "                         kernel_initializer=\"he_normal\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    u4 = up_block(input_tensor = b,\n",
    "                  no_filters = filter_size[3],\n",
    "                  skip_connection = d4,\n",
    "                  kernel_size=(3, 3),\n",
    "                  strides=(1, 1),\n",
    "                  upsampling_factor = (2,2),\n",
    "                  max_pool_window = (2,2),\n",
    "                  padding=\"same\",\n",
    "                  kernel_initializer=\"he_normal\")\n",
    "    \n",
    "    u3 = up_block(input_tensor = u4,\n",
    "                  no_filters = filter_size[2],\n",
    "                  skip_connection = d3,\n",
    "                  kernel_size=(3, 3),\n",
    "                  strides=(1, 1),\n",
    "                  upsampling_factor = (2,2),\n",
    "                  max_pool_window = (2,2),\n",
    "                  padding=\"same\",\n",
    "                  kernel_initializer=\"he_normal\")\n",
    "    \n",
    "    \n",
    "    u2 = up_block(input_tensor = u3,\n",
    "                  no_filters = filter_size[1],\n",
    "                  skip_connection = d2,\n",
    "                  kernel_size=(3, 3),\n",
    "                  strides=(1, 1),\n",
    "                  upsampling_factor = (2,2),\n",
    "                  max_pool_window = (2,2),\n",
    "                  padding=\"same\",\n",
    "                  kernel_initializer=\"he_normal\")\n",
    "    \n",
    "    \n",
    "    u1 = up_block(input_tensor = u2,\n",
    "                  no_filters = filter_size[0],\n",
    "                  skip_connection = d1,\n",
    "                  kernel_size=(3, 3),\n",
    "                  strides=(1, 1),\n",
    "                  upsampling_factor = (2,2),\n",
    "                  max_pool_window = (2,2),\n",
    "                  padding=\"same\",\n",
    "                  kernel_initializer=\"he_normal\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    output = output_block(input_tensor=u1 , \n",
    "                         padding = \"same\",\n",
    "                         kernel_initializer= \"he_normal\")\n",
    "    \n",
    "    model = keras.models.Model(inputs = inputs , outputs = output)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xVbsBQnJfOlz"
   },
   "outputs": [],
   "source": [
    "model = UNet(input_shape = (128,128,3))\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpPfRQyrfVtl"
   },
   "outputs": [],
   "source": [
    "image_size = 128 \n",
    "epochs = 10\n",
    "batch_size = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7uP2BG9gX9Y"
   },
   "outputs": [],
   "source": [
    "train_gen = DataGen(path_input = \"/content/train2014\" , path_mask = \"/content/mask_train_2014/\" , batch_size = batch_size , image_size = image_size)\n",
    "val_gen = DataGen(path_input =  \"/content/val2014\", path_mask =  \"/content/mask_val_2014\", batch_size = batch_size , image_size = image_size)\n",
    "\n",
    "\n",
    "train_steps =  len(os.listdir( \"/content/train2014\"))/batch_size\n",
    "\n",
    "\n",
    "model.fit_generator(train_gen , validation_data = val_gen , steps_per_epoch = train_steps , epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykqwnhtNhtFe"
   },
   "outputs": [],
   "source": [
    "x, y = val_gen.__getitem__(4)\n",
    "result = model.predict(x)\n",
    "\n",
    "result = result > 0.5\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(np.reshape(y[0]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(np.reshape(result[0]*255, (image_size, image_size)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQqf0lvjk-jo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras_COCO_UNET.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
